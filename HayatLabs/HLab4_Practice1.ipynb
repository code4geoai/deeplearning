{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aadc1dd0",
   "metadata": {},
   "source": [
    "This is the pracctice 1 session of debiasing Facial Recognitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e06da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Imports\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch\n",
    "import mitdeeplearning as mdl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33af603f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists\n"
     ]
    }
   ],
   "source": [
    "# Dataset Download\n",
    "CACHE_DIR = Path.cwd() /\".cache\"/\"mitdeeplearning\"\n",
    "CACHE_DIR.mkdir (parents= True, exist_ok= True)\n",
    "\n",
    "path_to_training_data = CACHE_DIR.joinpath(\"train_face.h5\")\n",
    "\n",
    "#Check to avoid re-downloading\n",
    "if path_to_training_data.is_file():\n",
    "    print(\"Data already exists\")\n",
    "else:\n",
    "    url = \"https://www.dropbox.com/s/hlz8atheyozp1yx/train_face.h5?dl=1\"\n",
    "    torch.hub.download_url_to_file(url,path_to_training_data)\n",
    "    print(\"Dowloading data to: {path_to_training_data} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c7a107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening d:\\DL_Repos\\introtodeeplearning\\HayatLabs\\.cache\\mitdeeplearning\\train_face.h5\n",
      "Loading data into memory...\n"
     ]
    }
   ],
   "source": [
    "# 3A. DataLoader\n",
    "\n",
    "channels_last = False\n",
    "loader = mdl.lab2.TrainingDatasetLoader(path_to_training_data,channels_last=channels_last)\n",
    "\n",
    "images, labels = loader.get_batch(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "300c0aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training dataset: 109914\n",
      "Bach_size:100, Channels: 3, Height:64, Width:64\n"
     ]
    }
   ],
   "source": [
    "#3B Checking data size and dimensions\n",
    "\n",
    "dataset_size = loader.get_train_size()\n",
    "print(f\"Size of training dataset: {dataset_size}\")\n",
    "\n",
    "B,C,H,W = images.shape\n",
    "print(f\"Bach_size:{B}, Channels: {C}, Height:{H}, Width:{W}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93825bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Labels: (100, 1) Shows that it is a 2-D Array having Rows: 100 and Columns: 1\n",
      "Faces (Where label =1) : (array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
      "       67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83,\n",
      "       84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]))\n",
      "Selecting First array (Faces): [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
      " 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      " 98 99]\n",
      "Selecting 2nd Array (non-faces):[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0] \n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Labels: {labels.shape} Shows that it is a {labels.ndim}-D Array having Rows: {labels.shape[0]} and Columns: {labels.shape[1]}\") \n",
    "\n",
    "lab = np.where(labels==1)\n",
    "faces = lab[0]\n",
    "no_faces = lab[1]\n",
    "print(f\"Faces (Where label =1) : {lab}\") # it provided a tupal of arrays\n",
    "\n",
    "print(f\"Selecting First array (Faces): {faces}\") #selecting the first element of the array\n",
    "print(f\"Selecting 2nd Array (non-faces):{no_faces} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbafda2",
   "metadata": {},
   "source": [
    "# 4 Display of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebce7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df0464bb5d14125ada364ef96e161d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx_face', max=49), IntSlider(value=0, description='idx_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_images(idx_face=0, idx_notface=0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_images(idx_face=0, idx_notface = 0):\n",
    "    face_img = images[faces].transpose(0,2,3,1)\n",
    "    notface_img = images[no_faces].transpose(0,2,3,1)\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(face_img[idx_face])\n",
    "    plt.title(\"faces\")\n",
    "    plt.grid(False)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(notface_img[idx_notface])\n",
    "    plt.title(\"Not Face\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "widgets.interact(show_images, idx_face=(0,49), idx_notface=(0,49))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
